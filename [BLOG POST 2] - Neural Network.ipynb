{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3768a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from src.constants import Constants2, params_blog_2, hyperparameter_space\n",
    "import warnings\n",
    "from keras.models import Sequential\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense, multiply, Dropout # for creating regular densely-connected NN layers.\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from typing import *\n",
    "from time import time\n",
    "from src.utils import *\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import random\n",
    "import shap\n",
    "import math\n",
    "from mango import Tuner\n",
    "from itertools import product\n",
    "from hyperopt import hp, fmin, tpe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439e1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/RonRichman/AI_in_Actuarial_Science/blob/master/NL%20Pricing/Keras%20-%20NL%20Pricing%20-%20NN_embed_transfer.R#L177\n",
    "# https://www.analyticsvidhya.com/blog/2020/03/6-python-libraries-interpret-machine-learning-models/\n",
    "# https://towardsdatascience.com/interpretability-of-deep-learning-models-9f52e54d72ab\n",
    "# https://towardsdatascience.com/feed-forward-neural-networks-how-to-successfully-build-them-in-python-74503409d99a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18be0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.float_format','{:,.4f}'.format)\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908c5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = params_blog_2.get(Constants2.RANDOM_STATE)\n",
    "TEST_SIZE = params_blog_2.get(Constants2.TEST_SIZE)\n",
    "VAL_SIZE = params_blog_2.get(Constants2.VAL_SIZE_FROM_TRAIN_SIZE)\n",
    "N_ITER_SKLEARN_HYPEROPT = params_blog_2.get(Constants2.N_ITER_SKLEARN_HYPEROPT)\n",
    "N_ITER= N_ITER_SKLEARN_HYPEROPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21eaa3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = params_blog_2.get(Constants2.PATH_TO_DATA)\n",
    "nb_claims_name, claim_amount_name = params_blog_2.get(Constants2.NB_CLAIMS), params_blog_2.get(Constants2.CLAIM_AMOUNT)\n",
    "claim_frequency_name = params_blog_2.get(Constants2.CLAIM_FREQUENCY)\n",
    "exposure_name = params_blog_2.get(Constants2.EXPOSURE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e5fd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.read_pickle(os.path.join(PATH_TO_DATA, params_blog_2.get(Constants2.DATASET_FREQ_NAME)))\n",
    "df_sev = pd.read_pickle(os.path.join(PATH_TO_DATA, params_blog_2.get(Constants2.DATASET_SEV_NAME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978fa1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ClaimNb</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exposure</th>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.8400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClaimAmount</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_frequency</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_d</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_e</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_f</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_g</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_h</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_i</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_j</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_k</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_l</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_n</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_o</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_fiat</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_mercedes_chrysler_bmw</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_opel_generalmotors_ford</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_renault_nissan_citroen</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_volkswagen_audi_skoda_seat</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_other</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gas_regular</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_aquitaine</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_basse_normandie</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_bretagne</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_centre</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_ile_de_france</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_limousin</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_nord_pas_de_calais</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_pays_de_la_loire</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_poitou_charentes</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driverage_bin_18_to_32</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driverage_bin_32_to_40</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driverage_bin_40_to_48</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>driverage_bin_48_to_57</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carage_bin_2_to_5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carage_bin_5_to_9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carage_bin_9_to_13</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carage_bin_13_to_100</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_bin_51_to_150</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_bin_150_to_555</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_bin_555_to_2404</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density_bin_2404_27000</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0      1\n",
       "ClaimNb                          0.0000 0.0000\n",
       "Exposure                         0.0900 0.8400\n",
       "ClaimAmount                      0.0000 0.0000\n",
       "claim_frequency                  0.0000 0.0000\n",
       "power_d                          0.0000 0.0000\n",
       "power_e                          0.0000 0.0000\n",
       "power_f                          0.0000 0.0000\n",
       "power_g                          1.0000 1.0000\n",
       "power_h                          0.0000 0.0000\n",
       "power_i                          0.0000 0.0000\n",
       "power_j                          0.0000 0.0000\n",
       "power_k                          0.0000 0.0000\n",
       "power_l                          0.0000 0.0000\n",
       "power_n                          0.0000 0.0000\n",
       "power_o                          0.0000 0.0000\n",
       "brand_fiat                       0.0000 0.0000\n",
       "brand_mercedes_chrysler_bmw      0.0000 0.0000\n",
       "brand_opel_generalmotors_ford    0.0000 0.0000\n",
       "brand_renault_nissan_citroen     0.0000 0.0000\n",
       "brand_volkswagen_audi_skoda_seat 0.0000 0.0000\n",
       "brand_other                      0.0000 0.0000\n",
       "gas_regular                      0.0000 0.0000\n",
       "region_aquitaine                 1.0000 1.0000\n",
       "region_basse_normandie           0.0000 0.0000\n",
       "region_bretagne                  0.0000 0.0000\n",
       "region_centre                    0.0000 0.0000\n",
       "region_ile_de_france             0.0000 0.0000\n",
       "region_limousin                  0.0000 0.0000\n",
       "region_nord_pas_de_calais        0.0000 0.0000\n",
       "region_pays_de_la_loire          0.0000 0.0000\n",
       "region_poitou_charentes          0.0000 0.0000\n",
       "driverage_bin_18_to_32           0.0000 0.0000\n",
       "driverage_bin_32_to_40           0.0000 0.0000\n",
       "driverage_bin_40_to_48           1.0000 1.0000\n",
       "driverage_bin_48_to_57           0.0000 0.0000\n",
       "carage_bin_2_to_5                0.0000 0.0000\n",
       "carage_bin_5_to_9                0.0000 0.0000\n",
       "carage_bin_9_to_13               0.0000 0.0000\n",
       "carage_bin_13_to_100             0.0000 0.0000\n",
       "density_bin_51_to_150            1.0000 1.0000\n",
       "density_bin_150_to_555           0.0000 0.0000\n",
       "density_bin_555_to_2404          0.0000 0.0000\n",
       "density_bin_2404_27000           0.0000 0.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.head(2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220d82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_claims, claim_amount = df_freq[nb_claims_name], df_freq[claim_amount_name]\n",
    "X = df_freq.drop(columns=[claim_amount_name, claim_frequency_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3bba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(X, nb_claims, \n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                    stratify=X[nb_claims_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32297d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, \n",
    "                                                    test_size=VAL_SIZE, \n",
    "                                                    random_state=RANDOM_STATE,\n",
    "                                                   stratify=x_train_val[nb_claims_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f4f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_train, exp_val, exp_test = x_train[exposure_name], x_val[exposure_name], x_test[exposure_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad7db865",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns=[nb_claims_name])\n",
    "x_val = x_val.drop(columns=[nb_claims_name])\n",
    "x_test = x_test.drop(columns=[nb_claims_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d34efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- 0th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'sigmoid',\n",
      "                   'dropout_rate': 0.15000000000000002,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 100,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': 'softmax',\n",
      "                   'dropout_rate': 0.24000000000000002,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 45,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 2,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1144/1163 [============================>.] - ETA: 0s - loss: 0.3783 - poisson: 0.3783WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 4s 3ms/step - loss: 0.3761 - poisson: 0.3761 - val_loss: 0.2132 - val_poisson: 0.2132\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.2075 - poisson: 0.2075 - val_loss: 0.1719 - val_poisson: 0.1719\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1834 - poisson: 0.1834 - val_loss: 0.1661 - val_poisson: 0.1661\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1768 - poisson: 0.1768 - val_loss: 0.1655 - val_poisson: 0.1655\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1699 - poisson: 0.1699 - val_loss: 0.1636 - val_poisson: 0.1636\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1665 - poisson: 0.1665 - val_loss: 0.1625 - val_poisson: 0.1625\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1645 - poisson: 0.1645 - val_loss: 0.1614 - val_poisson: 0.1614\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1633 - poisson: 0.1633 - val_loss: 0.1610 - val_poisson: 0.1610\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1625 - poisson: 0.1625 - val_loss: 0.1612 - val_poisson: 0.1612\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1622 - poisson: 0.1622 - val_loss: 0.1609 - val_poisson: 0.1609\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 780us/step\n",
      "-------------------------------------------------- 1th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'tanh',\n",
      "                   'dropout_rate': 0.12,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 50,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': None,\n",
      "                   'dropout_rate': 0.26,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 45,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 2,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1143/1163 [============================>.] - ETA: 0s - loss: 0.1772 - poisson: 0.1772WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1771 - poisson: 0.1771 - val_loss: 0.1627 - val_poisson: 0.1627\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1668 - poisson: 0.1668 - val_loss: 0.1629 - val_poisson: 0.1629\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1655 - poisson: 0.1655 - val_loss: 0.1627 - val_poisson: 0.1627\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1648 - poisson: 0.1648 - val_loss: 0.1621 - val_poisson: 0.1621\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1645 - poisson: 0.1645 - val_loss: 0.1619 - val_poisson: 0.1619\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1641 - poisson: 0.1641 - val_loss: 0.1617 - val_poisson: 0.1617\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1636 - poisson: 0.1636 - val_loss: 0.1619 - val_poisson: 0.1619\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1636 - poisson: 0.1636 - val_loss: 0.1618 - val_poisson: 0.1618\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1632 - poisson: 0.1632 - val_loss: 0.1618 - val_poisson: 0.1618\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1632 - poisson: 0.1632 - val_loss: 0.1618 - val_poisson: 0.1618\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 742us/step\n",
      "-------------------------------------------------- 2th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'softmax',\n",
      "                   'dropout_rate': 0.08,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 75,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': None,\n",
      "                   'dropout_rate': 0.22,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 100,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_2': {'activation': 'softmax',\n",
      "                   'dropout_rate': 0.13,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 2,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 3,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 40).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148/1163 [============================>.] - ETA: 0s - loss: 0.2809 - poisson: 0.2809WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.2802 - poisson: 0.2802 - val_loss: 0.1777 - val_poisson: 0.1777\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.2008 - poisson: 0.2008 - val_loss: 0.1664 - val_poisson: 0.1664\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1853 - poisson: 0.1853 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1774 - poisson: 0.1774 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1722 - poisson: 0.1722 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1691 - poisson: 0.1691 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 3s 3ms/step - loss: 0.1676 - poisson: 0.1676 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1669 - poisson: 0.1669 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1665 - poisson: 0.1665 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1663 - poisson: 0.1663 - val_loss: 0.1659 - val_poisson: 0.1659\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 908us/step\n",
      "-------------------------------------------------- 3th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'tanh',\n",
      "                   'dropout_rate': 0.34,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 40,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': 'relu',\n",
      "                   'dropout_rate': 0.24000000000000002,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 20,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 2,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1146/1163 [============================>.] - ETA: 0s - loss: 0.1907 - poisson: 0.1907WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1902 - poisson: 0.1902 - val_loss: 0.1639 - val_poisson: 0.1639\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1717 - poisson: 0.1717 - val_loss: 0.1626 - val_poisson: 0.1626\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1688 - poisson: 0.1688 - val_loss: 0.1624 - val_poisson: 0.1624\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1666 - poisson: 0.1666 - val_loss: 0.1621 - val_poisson: 0.1621\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1653 - poisson: 0.1653 - val_loss: 0.1617 - val_poisson: 0.1617\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1646 - poisson: 0.1646 - val_loss: 0.1612 - val_poisson: 0.1612\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1636 - poisson: 0.1636 - val_loss: 0.1610 - val_poisson: 0.1610\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1632 - poisson: 0.1632 - val_loss: 0.1610 - val_poisson: 0.1610\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1626 - poisson: 0.1626 - val_loss: 0.1608 - val_poisson: 0.1608\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1621 - poisson: 0.1621 - val_loss: 0.1605 - val_poisson: 0.1605\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_4'), name='input_4', description=\"created by layer 'input_4'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 784us/step\n",
      "-------------------------------------------------- 4th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'relu',\n",
      "                   'dropout_rate': 0.32,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 100,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': 'softmax',\n",
      "                   'dropout_rate': 0.2,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 100,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 2,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1153/1163 [============================>.] - ETA: 0s - loss: 0.4046 - poisson: 0.4046WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.4035 - poisson: 0.4035 - val_loss: 0.2132 - val_poisson: 0.2132\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.2198 - poisson: 0.2198 - val_loss: 0.1793 - val_poisson: 0.1793\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 3s 3ms/step - loss: 0.1816 - poisson: 0.1816 - val_loss: 0.1665 - val_poisson: 0.1665\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1736 - poisson: 0.1736 - val_loss: 0.1634 - val_poisson: 0.1634\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 3s 3ms/step - loss: 0.1677 - poisson: 0.1677 - val_loss: 0.1619 - val_poisson: 0.1619\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 3s 3ms/step - loss: 0.1650 - poisson: 0.1650 - val_loss: 0.1612 - val_poisson: 0.1612\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1632 - poisson: 0.1632 - val_loss: 0.1609 - val_poisson: 0.1609\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1625 - poisson: 0.1625 - val_loss: 0.1610 - val_poisson: 0.1610\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1618 - poisson: 0.1618 - val_loss: 0.1608 - val_poisson: 0.1608\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.1613 - poisson: 0.1613 - val_loss: 0.1605 - val_poisson: 0.1605\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 818us/step\n",
      "-------------------------------------------------- 5th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': None,\n",
      "                   'dropout_rate': 0.11,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 25,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 1,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1158/1163 [============================>.] - ETA: 0s - loss: 0.2126 - poisson: 0.2126WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.2125 - poisson: 0.2125 - val_loss: 0.1690 - val_poisson: 0.1690\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 2s 1ms/step - loss: 0.1691 - poisson: 0.1691 - val_loss: 0.1647 - val_poisson: 0.1647\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1661 - poisson: 0.1661 - val_loss: 0.1631 - val_poisson: 0.1631\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1649 - poisson: 0.1649 - val_loss: 0.1626 - val_poisson: 0.1626\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1644 - poisson: 0.1644 - val_loss: 0.1624 - val_poisson: 0.1624\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1639 - poisson: 0.1639 - val_loss: 0.1625 - val_poisson: 0.1625\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 2s 1ms/step - loss: 0.1638 - poisson: 0.1638 - val_loss: 0.1620 - val_poisson: 0.1620\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 2s 1ms/step - loss: 0.1636 - poisson: 0.1636 - val_loss: 0.1622 - val_poisson: 0.1622\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 2s 1ms/step - loss: 0.1633 - poisson: 0.1633 - val_loss: 0.1619 - val_poisson: 0.1619\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 2s 1ms/step - loss: 0.1631 - poisson: 0.1631 - val_loss: 0.1619 - val_poisson: 0.1619\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 779us/step\n",
      "-------------------------------------------------- 6th EXPERIMENT --------------------------------------------------\n",
      "{'batch_size': 256,\n",
      " 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>],\n",
      " 'layer_param_0': {'activation': 'relu',\n",
      "                   'dropout_rate': 0.04,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 30,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_1': {'activation': None,\n",
      "                   'dropout_rate': 0.32,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 2,\n",
      "                   'use_bias': True},\n",
      " 'layer_param_2': {'activation': 'tanh',\n",
      "                   'dropout_rate': 0.39,\n",
      "                   'kernel_initializer': 'glorot_uniform',\n",
      "                   'units': 40,\n",
      "                   'use_bias': True},\n",
      " 'nb_hidden_layers': 3,\n",
      " 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1144/1163 [============================>.] - ETA: 0s - loss: 0.2088 - poisson: 0.2088WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "1163/1163 [==============================] - 3s 2ms/step - loss: 0.2083 - poisson: 0.2083 - val_loss: 0.1651 - val_poisson: 0.1651\n",
      "Epoch 2/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1682 - poisson: 0.1682 - val_loss: 0.1624 - val_poisson: 0.1624\n",
      "Epoch 3/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1663 - poisson: 0.1663 - val_loss: 0.1616 - val_poisson: 0.1616\n",
      "Epoch 4/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1653 - poisson: 0.1653 - val_loss: 0.1614 - val_poisson: 0.1614\n",
      "Epoch 5/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1646 - poisson: 0.1646 - val_loss: 0.1614 - val_poisson: 0.1614\n",
      "Epoch 6/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1640 - poisson: 0.1640 - val_loss: 0.1608 - val_poisson: 0.1608\n",
      "Epoch 7/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1635 - poisson: 0.1635 - val_loss: 0.1612 - val_poisson: 0.1612\n",
      "Epoch 8/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1634 - poisson: 0.1634 - val_loss: 0.1610 - val_poisson: 0.1610\n",
      "Epoch 9/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1628 - poisson: 0.1628 - val_loss: 0.1607 - val_poisson: 0.1607\n",
      "Epoch 10/10\n",
      "1163/1163 [==============================] - 2s 2ms/step - loss: 0.1627 - poisson: 0.1627 - val_loss: 0.1608 - val_poisson: 0.1608\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 40), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "2583/2583 [==============================] - 2s 797us/step\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "results, best_model = run_optimization_neural_network(x_train, y_train, x_val, y_val, x_test, y_test, \n",
    "                                                      exp_test, hyperparameter_space,\n",
    "                                                      n_max_experiments=params_blog_2.get(Constants2.N_MAX_EXPERIMENTS),\n",
    "                                                      max_optimization_time=params_blog_2.get(Constants2.MAX_OPTIMIZATION_TIME),\n",
    "                                                     )\n",
    "opt_time = (time() - start_time)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24be2efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_hyperparams</th>\n",
       "      <th>poisson_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [&lt;keras.callbacks.EarlyStopping object at 0x000001A0142C5310&gt;], 'batch_size': 256, 'layer_param_0': {'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 100, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}</td>\n",
       "      <td>0.2974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [&lt;keras.callbacks.EarlyStopping object at 0x000001A0142C5310&gt;], 'batch_size': 256, 'layer_param_0': {'units': 40, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}</td>\n",
       "      <td>0.2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'nb_hidden_layers': 3, 'optimizer': 'adam', 'callbacks': [&lt;keras.callbacks.EarlyStopping object at 0x000001A0142C5310&gt;], 'batch_size': 256, 'layer_param_0': {'units': 30, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 2, 'activation': None, 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_2': {'units': 40, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}</td>\n",
       "      <td>0.2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [&lt;keras.callbacks.EarlyStopping object at 0x000001A0142C5310&gt;], 'batch_size': 256, 'layer_param_0': {'units': 100, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 45, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}</td>\n",
       "      <td>0.2993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [&lt;keras.callbacks.EarlyStopping object at 0x000001A0142C5310&gt;], 'batch_size': 256, 'layer_param_0': {'units': 50, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 45, 'activation': None, 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}</td>\n",
       "      <td>0.2997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                        selected_hyperparams  \\\n",
       "0                                                                                                          {'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>], 'batch_size': 256, 'layer_param_0': {'units': 100, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 100, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}   \n",
       "1                                                                                                               {'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>], 'batch_size': 256, 'layer_param_0': {'units': 40, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 20, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}   \n",
       "2  {'nb_hidden_layers': 3, 'optimizer': 'adam', 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>], 'batch_size': 256, 'layer_param_0': {'units': 30, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 2, 'activation': None, 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_2': {'units': 40, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}   \n",
       "3                                                                                                        {'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>], 'batch_size': 256, 'layer_param_0': {'units': 100, 'activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 45, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}   \n",
       "4                                                                                                                 {'nb_hidden_layers': 2, 'optimizer': 'adam', 'callbacks': [<keras.callbacks.EarlyStopping object at 0x000001A0142C5310>], 'batch_size': 256, 'layer_param_0': {'units': 50, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}, 'layer_param_1': {'units': 45, 'activation': None, 'use_bias': True, 'kernel_initializer': 'glorot_uniform'}}   \n",
       "\n",
       "   poisson_dev  \n",
       "0       0.2974  \n",
       "1       0.2976  \n",
       "2       0.2983  \n",
       "3       0.2993  \n",
       "4       0.2997  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.reset_index(inplace=True, drop=True)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ade88b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb_hidden_layers': 2,\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.EarlyStopping at 0x1a0142c5310>],\n",
       " 'batch_size': 256,\n",
       " 'layer_param_0': {'units': 100,\n",
       "  'activation': 'relu',\n",
       "  'use_bias': True,\n",
       "  'kernel_initializer': 'glorot_uniform'},\n",
       " 'layer_param_1': {'units': 100,\n",
       "  'activation': 'softmax',\n",
       "  'use_bias': True,\n",
       "  'kernel_initializer': 'glorot_uniform'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(1).selected_hyperparams.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43a5eeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sigmoid', 2, 0.01),\n",
       " ('sigmoid', 2, 0.02),\n",
       " ('sigmoid', 2, 0.03),\n",
       " ('sigmoid', 2, 0.04),\n",
       " ('sigmoid', 2, 0.05),\n",
       " ('sigmoid', 2, 0.060000000000000005),\n",
       " ('sigmoid', 2, 0.06999999999999999),\n",
       " ('sigmoid', 2, 0.08),\n",
       " ('sigmoid', 2, 0.09),\n",
       " ('sigmoid', 2, 0.09999999999999999),\n",
       " ('sigmoid', 2, 0.11),\n",
       " ('sigmoid', 2, 0.12),\n",
       " ('sigmoid', 2, 0.13),\n",
       " ('sigmoid', 2, 0.14),\n",
       " ('sigmoid', 2, 0.15000000000000002),\n",
       " ('sigmoid', 2, 0.16),\n",
       " ('sigmoid', 2, 0.17),\n",
       " ('sigmoid', 2, 0.18000000000000002),\n",
       " ('sigmoid', 2, 0.19),\n",
       " ('sigmoid', 2, 0.2),\n",
       " ('sigmoid', 2, 0.21000000000000002),\n",
       " ('sigmoid', 2, 0.22),\n",
       " ('sigmoid', 2, 0.23),\n",
       " ('sigmoid', 2, 0.24000000000000002),\n",
       " ('sigmoid', 2, 0.25),\n",
       " ('sigmoid', 2, 0.26),\n",
       " ('sigmoid', 2, 0.27),\n",
       " ('sigmoid', 2, 0.28),\n",
       " ('sigmoid', 2, 0.29000000000000004),\n",
       " ('sigmoid', 2, 0.3),\n",
       " ('sigmoid', 2, 0.31),\n",
       " ('sigmoid', 2, 0.32),\n",
       " ('sigmoid', 2, 0.33),\n",
       " ('sigmoid', 2, 0.34),\n",
       " ('sigmoid', 2, 0.35000000000000003),\n",
       " ('sigmoid', 2, 0.36000000000000004),\n",
       " ('sigmoid', 2, 0.37),\n",
       " ('sigmoid', 2, 0.38),\n",
       " ('sigmoid', 2, 0.39),\n",
       " ('sigmoid', 2, 0.4),\n",
       " ('sigmoid', 2, 0.41000000000000003),\n",
       " ('sigmoid', 2, 0.42000000000000004),\n",
       " ('sigmoid', 2, 0.43),\n",
       " ('sigmoid', 2, 0.44),\n",
       " ('sigmoid', 2, 0.45),\n",
       " ('sigmoid', 2, 0.46),\n",
       " ('sigmoid', 2, 0.47000000000000003),\n",
       " ('sigmoid', 2, 0.48000000000000004),\n",
       " ('sigmoid', 2, 0.49),\n",
       " ('sigmoid', 2, 0.5),\n",
       " ('sigmoid', 5, 0.01),\n",
       " ('sigmoid', 5, 0.02),\n",
       " ('sigmoid', 5, 0.03),\n",
       " ('sigmoid', 5, 0.04),\n",
       " ('sigmoid', 5, 0.05),\n",
       " ('sigmoid', 5, 0.060000000000000005),\n",
       " ('sigmoid', 5, 0.06999999999999999),\n",
       " ('sigmoid', 5, 0.08),\n",
       " ('sigmoid', 5, 0.09),\n",
       " ('sigmoid', 5, 0.09999999999999999),\n",
       " ('sigmoid', 5, 0.11),\n",
       " ('sigmoid', 5, 0.12),\n",
       " ('sigmoid', 5, 0.13),\n",
       " ('sigmoid', 5, 0.14),\n",
       " ('sigmoid', 5, 0.15000000000000002),\n",
       " ('sigmoid', 5, 0.16),\n",
       " ('sigmoid', 5, 0.17),\n",
       " ('sigmoid', 5, 0.18000000000000002),\n",
       " ('sigmoid', 5, 0.19),\n",
       " ('sigmoid', 5, 0.2),\n",
       " ('sigmoid', 5, 0.21000000000000002),\n",
       " ('sigmoid', 5, 0.22),\n",
       " ('sigmoid', 5, 0.23),\n",
       " ('sigmoid', 5, 0.24000000000000002),\n",
       " ('sigmoid', 5, 0.25),\n",
       " ('sigmoid', 5, 0.26),\n",
       " ('sigmoid', 5, 0.27),\n",
       " ('sigmoid', 5, 0.28),\n",
       " ('sigmoid', 5, 0.29000000000000004),\n",
       " ('sigmoid', 5, 0.3),\n",
       " ('sigmoid', 5, 0.31),\n",
       " ('sigmoid', 5, 0.32),\n",
       " ('sigmoid', 5, 0.33),\n",
       " ('sigmoid', 5, 0.34),\n",
       " ('sigmoid', 5, 0.35000000000000003),\n",
       " ('sigmoid', 5, 0.36000000000000004),\n",
       " ('sigmoid', 5, 0.37),\n",
       " ('sigmoid', 5, 0.38),\n",
       " ('sigmoid', 5, 0.39),\n",
       " ('sigmoid', 5, 0.4),\n",
       " ('sigmoid', 5, 0.41000000000000003),\n",
       " ('sigmoid', 5, 0.42000000000000004),\n",
       " ('sigmoid', 5, 0.43),\n",
       " ('sigmoid', 5, 0.44),\n",
       " ('sigmoid', 5, 0.45),\n",
       " ('sigmoid', 5, 0.46),\n",
       " ('sigmoid', 5, 0.47000000000000003),\n",
       " ('sigmoid', 5, 0.48000000000000004),\n",
       " ('sigmoid', 5, 0.49),\n",
       " ('sigmoid', 5, 0.5),\n",
       " ('sigmoid', 10, 0.01),\n",
       " ('sigmoid', 10, 0.02),\n",
       " ('sigmoid', 10, 0.03),\n",
       " ('sigmoid', 10, 0.04),\n",
       " ('sigmoid', 10, 0.05),\n",
       " ('sigmoid', 10, 0.060000000000000005),\n",
       " ('sigmoid', 10, 0.06999999999999999),\n",
       " ('sigmoid', 10, 0.08),\n",
       " ('sigmoid', 10, 0.09),\n",
       " ('sigmoid', 10, 0.09999999999999999),\n",
       " ('sigmoid', 10, 0.11),\n",
       " ('sigmoid', 10, 0.12),\n",
       " ('sigmoid', 10, 0.13),\n",
       " ('sigmoid', 10, 0.14),\n",
       " ('sigmoid', 10, 0.15000000000000002),\n",
       " ('sigmoid', 10, 0.16),\n",
       " ('sigmoid', 10, 0.17),\n",
       " ('sigmoid', 10, 0.18000000000000002),\n",
       " ('sigmoid', 10, 0.19),\n",
       " ('sigmoid', 10, 0.2),\n",
       " ('sigmoid', 10, 0.21000000000000002),\n",
       " ('sigmoid', 10, 0.22),\n",
       " ('sigmoid', 10, 0.23),\n",
       " ('sigmoid', 10, 0.24000000000000002),\n",
       " ('sigmoid', 10, 0.25),\n",
       " ('sigmoid', 10, 0.26),\n",
       " ('sigmoid', 10, 0.27),\n",
       " ('sigmoid', 10, 0.28),\n",
       " ('sigmoid', 10, 0.29000000000000004),\n",
       " ('sigmoid', 10, 0.3),\n",
       " ('sigmoid', 10, 0.31),\n",
       " ('sigmoid', 10, 0.32),\n",
       " ('sigmoid', 10, 0.33),\n",
       " ('sigmoid', 10, 0.34),\n",
       " ('sigmoid', 10, 0.35000000000000003),\n",
       " ('sigmoid', 10, 0.36000000000000004),\n",
       " ('sigmoid', 10, 0.37),\n",
       " ('sigmoid', 10, 0.38),\n",
       " ('sigmoid', 10, 0.39),\n",
       " ('sigmoid', 10, 0.4),\n",
       " ('sigmoid', 10, 0.41000000000000003),\n",
       " ('sigmoid', 10, 0.42000000000000004),\n",
       " ('sigmoid', 10, 0.43),\n",
       " ('sigmoid', 10, 0.44),\n",
       " ('sigmoid', 10, 0.45),\n",
       " ('sigmoid', 10, 0.46),\n",
       " ('sigmoid', 10, 0.47000000000000003),\n",
       " ('sigmoid', 10, 0.48000000000000004),\n",
       " ('sigmoid', 10, 0.49),\n",
       " ('sigmoid', 10, 0.5),\n",
       " ('sigmoid', 15, 0.01),\n",
       " ('sigmoid', 15, 0.02),\n",
       " ('sigmoid', 15, 0.03),\n",
       " ('sigmoid', 15, 0.04),\n",
       " ('sigmoid', 15, 0.05),\n",
       " ('sigmoid', 15, 0.060000000000000005),\n",
       " ('sigmoid', 15, 0.06999999999999999),\n",
       " ('sigmoid', 15, 0.08),\n",
       " ('sigmoid', 15, 0.09),\n",
       " ('sigmoid', 15, 0.09999999999999999),\n",
       " ('sigmoid', 15, 0.11),\n",
       " ('sigmoid', 15, 0.12),\n",
       " ('sigmoid', 15, 0.13),\n",
       " ('sigmoid', 15, 0.14),\n",
       " ('sigmoid', 15, 0.15000000000000002),\n",
       " ('sigmoid', 15, 0.16),\n",
       " ('sigmoid', 15, 0.17),\n",
       " ('sigmoid', 15, 0.18000000000000002),\n",
       " ('sigmoid', 15, 0.19),\n",
       " ('sigmoid', 15, 0.2),\n",
       " ('sigmoid', 15, 0.21000000000000002),\n",
       " ('sigmoid', 15, 0.22),\n",
       " ('sigmoid', 15, 0.23),\n",
       " ('sigmoid', 15, 0.24000000000000002),\n",
       " ('sigmoid', 15, 0.25),\n",
       " ('sigmoid', 15, 0.26),\n",
       " ('sigmoid', 15, 0.27),\n",
       " ('sigmoid', 15, 0.28),\n",
       " ('sigmoid', 15, 0.29000000000000004),\n",
       " ('sigmoid', 15, 0.3),\n",
       " ('sigmoid', 15, 0.31),\n",
       " ('sigmoid', 15, 0.32),\n",
       " ('sigmoid', 15, 0.33),\n",
       " ('sigmoid', 15, 0.34),\n",
       " ('sigmoid', 15, 0.35000000000000003),\n",
       " ('sigmoid', 15, 0.36000000000000004),\n",
       " ('sigmoid', 15, 0.37),\n",
       " ('sigmoid', 15, 0.38),\n",
       " ('sigmoid', 15, 0.39),\n",
       " ('sigmoid', 15, 0.4),\n",
       " ('sigmoid', 15, 0.41000000000000003),\n",
       " ('sigmoid', 15, 0.42000000000000004),\n",
       " ('sigmoid', 15, 0.43),\n",
       " ('sigmoid', 15, 0.44),\n",
       " ('sigmoid', 15, 0.45),\n",
       " ('sigmoid', 15, 0.46),\n",
       " ('sigmoid', 15, 0.47000000000000003),\n",
       " ('sigmoid', 15, 0.48000000000000004),\n",
       " ('sigmoid', 15, 0.49),\n",
       " ('sigmoid', 15, 0.5),\n",
       " ('sigmoid', 20, 0.01),\n",
       " ('sigmoid', 20, 0.02),\n",
       " ('sigmoid', 20, 0.03),\n",
       " ('sigmoid', 20, 0.04),\n",
       " ('sigmoid', 20, 0.05),\n",
       " ('sigmoid', 20, 0.060000000000000005),\n",
       " ('sigmoid', 20, 0.06999999999999999),\n",
       " ('sigmoid', 20, 0.08),\n",
       " ('sigmoid', 20, 0.09),\n",
       " ('sigmoid', 20, 0.09999999999999999),\n",
       " ('sigmoid', 20, 0.11),\n",
       " ('sigmoid', 20, 0.12),\n",
       " ('sigmoid', 20, 0.13),\n",
       " ('sigmoid', 20, 0.14),\n",
       " ('sigmoid', 20, 0.15000000000000002),\n",
       " ('sigmoid', 20, 0.16),\n",
       " ('sigmoid', 20, 0.17),\n",
       " ('sigmoid', 20, 0.18000000000000002),\n",
       " ('sigmoid', 20, 0.19),\n",
       " ('sigmoid', 20, 0.2),\n",
       " ('sigmoid', 20, 0.21000000000000002),\n",
       " ('sigmoid', 20, 0.22),\n",
       " ('sigmoid', 20, 0.23),\n",
       " ('sigmoid', 20, 0.24000000000000002),\n",
       " ('sigmoid', 20, 0.25),\n",
       " ('sigmoid', 20, 0.26),\n",
       " ('sigmoid', 20, 0.27),\n",
       " ('sigmoid', 20, 0.28),\n",
       " ('sigmoid', 20, 0.29000000000000004),\n",
       " ('sigmoid', 20, 0.3),\n",
       " ('sigmoid', 20, 0.31),\n",
       " ('sigmoid', 20, 0.32),\n",
       " ('sigmoid', 20, 0.33),\n",
       " ('sigmoid', 20, 0.34),\n",
       " ('sigmoid', 20, 0.35000000000000003),\n",
       " ('sigmoid', 20, 0.36000000000000004),\n",
       " ('sigmoid', 20, 0.37),\n",
       " ('sigmoid', 20, 0.38),\n",
       " ('sigmoid', 20, 0.39),\n",
       " ('sigmoid', 20, 0.4),\n",
       " ('sigmoid', 20, 0.41000000000000003),\n",
       " ('sigmoid', 20, 0.42000000000000004),\n",
       " ('sigmoid', 20, 0.43),\n",
       " ('sigmoid', 20, 0.44),\n",
       " ('sigmoid', 20, 0.45),\n",
       " ('sigmoid', 20, 0.46),\n",
       " ('sigmoid', 20, 0.47000000000000003),\n",
       " ('sigmoid', 20, 0.48000000000000004),\n",
       " ('sigmoid', 20, 0.49),\n",
       " ('sigmoid', 20, 0.5),\n",
       " ('sigmoid', 25, 0.01),\n",
       " ('sigmoid', 25, 0.02),\n",
       " ('sigmoid', 25, 0.03),\n",
       " ('sigmoid', 25, 0.04),\n",
       " ('sigmoid', 25, 0.05),\n",
       " ('sigmoid', 25, 0.060000000000000005),\n",
       " ('sigmoid', 25, 0.06999999999999999),\n",
       " ('sigmoid', 25, 0.08),\n",
       " ('sigmoid', 25, 0.09),\n",
       " ('sigmoid', 25, 0.09999999999999999),\n",
       " ('sigmoid', 25, 0.11),\n",
       " ('sigmoid', 25, 0.12),\n",
       " ('sigmoid', 25, 0.13),\n",
       " ('sigmoid', 25, 0.14),\n",
       " ('sigmoid', 25, 0.15000000000000002),\n",
       " ('sigmoid', 25, 0.16),\n",
       " ('sigmoid', 25, 0.17),\n",
       " ('sigmoid', 25, 0.18000000000000002),\n",
       " ('sigmoid', 25, 0.19),\n",
       " ('sigmoid', 25, 0.2),\n",
       " ('sigmoid', 25, 0.21000000000000002),\n",
       " ('sigmoid', 25, 0.22),\n",
       " ('sigmoid', 25, 0.23),\n",
       " ('sigmoid', 25, 0.24000000000000002),\n",
       " ('sigmoid', 25, 0.25),\n",
       " ('sigmoid', 25, 0.26),\n",
       " ('sigmoid', 25, 0.27),\n",
       " ('sigmoid', 25, 0.28),\n",
       " ('sigmoid', 25, 0.29000000000000004),\n",
       " ('sigmoid', 25, 0.3),\n",
       " ('sigmoid', 25, 0.31),\n",
       " ('sigmoid', 25, 0.32),\n",
       " ('sigmoid', 25, 0.33),\n",
       " ('sigmoid', 25, 0.34),\n",
       " ('sigmoid', 25, 0.35000000000000003),\n",
       " ('sigmoid', 25, 0.36000000000000004),\n",
       " ('sigmoid', 25, 0.37),\n",
       " ('sigmoid', 25, 0.38),\n",
       " ('sigmoid', 25, 0.39),\n",
       " ('sigmoid', 25, 0.4),\n",
       " ('sigmoid', 25, 0.41000000000000003),\n",
       " ('sigmoid', 25, 0.42000000000000004),\n",
       " ('sigmoid', 25, 0.43),\n",
       " ('sigmoid', 25, 0.44),\n",
       " ('sigmoid', 25, 0.45),\n",
       " ('sigmoid', 25, 0.46),\n",
       " ('sigmoid', 25, 0.47000000000000003),\n",
       " ('sigmoid', 25, 0.48000000000000004),\n",
       " ('sigmoid', 25, 0.49),\n",
       " ('sigmoid', 25, 0.5),\n",
       " ('sigmoid', 30, 0.01),\n",
       " ('sigmoid', 30, 0.02),\n",
       " ('sigmoid', 30, 0.03),\n",
       " ('sigmoid', 30, 0.04),\n",
       " ('sigmoid', 30, 0.05),\n",
       " ('sigmoid', 30, 0.060000000000000005),\n",
       " ('sigmoid', 30, 0.06999999999999999),\n",
       " ('sigmoid', 30, 0.08),\n",
       " ('sigmoid', 30, 0.09),\n",
       " ('sigmoid', 30, 0.09999999999999999),\n",
       " ('sigmoid', 30, 0.11),\n",
       " ('sigmoid', 30, 0.12),\n",
       " ('sigmoid', 30, 0.13),\n",
       " ('sigmoid', 30, 0.14),\n",
       " ('sigmoid', 30, 0.15000000000000002),\n",
       " ('sigmoid', 30, 0.16),\n",
       " ('sigmoid', 30, 0.17),\n",
       " ('sigmoid', 30, 0.18000000000000002),\n",
       " ('sigmoid', 30, 0.19),\n",
       " ('sigmoid', 30, 0.2),\n",
       " ('sigmoid', 30, 0.21000000000000002),\n",
       " ('sigmoid', 30, 0.22),\n",
       " ('sigmoid', 30, 0.23),\n",
       " ('sigmoid', 30, 0.24000000000000002),\n",
       " ('sigmoid', 30, 0.25),\n",
       " ('sigmoid', 30, 0.26),\n",
       " ('sigmoid', 30, 0.27),\n",
       " ('sigmoid', 30, 0.28),\n",
       " ('sigmoid', 30, 0.29000000000000004),\n",
       " ('sigmoid', 30, 0.3),\n",
       " ('sigmoid', 30, 0.31),\n",
       " ('sigmoid', 30, 0.32),\n",
       " ('sigmoid', 30, 0.33),\n",
       " ('sigmoid', 30, 0.34),\n",
       " ('sigmoid', 30, 0.35000000000000003),\n",
       " ('sigmoid', 30, 0.36000000000000004),\n",
       " ('sigmoid', 30, 0.37),\n",
       " ('sigmoid', 30, 0.38),\n",
       " ('sigmoid', 30, 0.39),\n",
       " ('sigmoid', 30, 0.4),\n",
       " ('sigmoid', 30, 0.41000000000000003),\n",
       " ('sigmoid', 30, 0.42000000000000004),\n",
       " ('sigmoid', 30, 0.43),\n",
       " ('sigmoid', 30, 0.44),\n",
       " ('sigmoid', 30, 0.45),\n",
       " ('sigmoid', 30, 0.46),\n",
       " ('sigmoid', 30, 0.47000000000000003),\n",
       " ('sigmoid', 30, 0.48000000000000004),\n",
       " ('sigmoid', 30, 0.49),\n",
       " ('sigmoid', 30, 0.5),\n",
       " ('sigmoid', 35, 0.01),\n",
       " ('sigmoid', 35, 0.02),\n",
       " ('sigmoid', 35, 0.03),\n",
       " ('sigmoid', 35, 0.04),\n",
       " ('sigmoid', 35, 0.05),\n",
       " ('sigmoid', 35, 0.060000000000000005),\n",
       " ('sigmoid', 35, 0.06999999999999999),\n",
       " ('sigmoid', 35, 0.08),\n",
       " ('sigmoid', 35, 0.09),\n",
       " ('sigmoid', 35, 0.09999999999999999),\n",
       " ('sigmoid', 35, 0.11),\n",
       " ('sigmoid', 35, 0.12),\n",
       " ('sigmoid', 35, 0.13),\n",
       " ('sigmoid', 35, 0.14),\n",
       " ('sigmoid', 35, 0.15000000000000002),\n",
       " ('sigmoid', 35, 0.16),\n",
       " ('sigmoid', 35, 0.17),\n",
       " ('sigmoid', 35, 0.18000000000000002),\n",
       " ('sigmoid', 35, 0.19),\n",
       " ('sigmoid', 35, 0.2),\n",
       " ('sigmoid', 35, 0.21000000000000002),\n",
       " ('sigmoid', 35, 0.22),\n",
       " ('sigmoid', 35, 0.23),\n",
       " ('sigmoid', 35, 0.24000000000000002),\n",
       " ('sigmoid', 35, 0.25),\n",
       " ('sigmoid', 35, 0.26),\n",
       " ('sigmoid', 35, 0.27),\n",
       " ('sigmoid', 35, 0.28),\n",
       " ('sigmoid', 35, 0.29000000000000004),\n",
       " ('sigmoid', 35, 0.3),\n",
       " ('sigmoid', 35, 0.31),\n",
       " ('sigmoid', 35, 0.32),\n",
       " ('sigmoid', 35, 0.33),\n",
       " ('sigmoid', 35, 0.34),\n",
       " ('sigmoid', 35, 0.35000000000000003),\n",
       " ('sigmoid', 35, 0.36000000000000004),\n",
       " ('sigmoid', 35, 0.37),\n",
       " ('sigmoid', 35, 0.38),\n",
       " ('sigmoid', 35, 0.39),\n",
       " ('sigmoid', 35, 0.4),\n",
       " ('sigmoid', 35, 0.41000000000000003),\n",
       " ('sigmoid', 35, 0.42000000000000004),\n",
       " ('sigmoid', 35, 0.43),\n",
       " ('sigmoid', 35, 0.44),\n",
       " ('sigmoid', 35, 0.45),\n",
       " ('sigmoid', 35, 0.46),\n",
       " ('sigmoid', 35, 0.47000000000000003),\n",
       " ('sigmoid', 35, 0.48000000000000004),\n",
       " ('sigmoid', 35, 0.49),\n",
       " ('sigmoid', 35, 0.5),\n",
       " ('sigmoid', 40, 0.01),\n",
       " ('sigmoid', 40, 0.02),\n",
       " ('sigmoid', 40, 0.03),\n",
       " ('sigmoid', 40, 0.04),\n",
       " ('sigmoid', 40, 0.05),\n",
       " ('sigmoid', 40, 0.060000000000000005),\n",
       " ('sigmoid', 40, 0.06999999999999999),\n",
       " ('sigmoid', 40, 0.08),\n",
       " ('sigmoid', 40, 0.09),\n",
       " ('sigmoid', 40, 0.09999999999999999),\n",
       " ('sigmoid', 40, 0.11),\n",
       " ('sigmoid', 40, 0.12),\n",
       " ('sigmoid', 40, 0.13),\n",
       " ('sigmoid', 40, 0.14),\n",
       " ('sigmoid', 40, 0.15000000000000002),\n",
       " ('sigmoid', 40, 0.16),\n",
       " ('sigmoid', 40, 0.17),\n",
       " ('sigmoid', 40, 0.18000000000000002),\n",
       " ('sigmoid', 40, 0.19),\n",
       " ('sigmoid', 40, 0.2),\n",
       " ('sigmoid', 40, 0.21000000000000002),\n",
       " ('sigmoid', 40, 0.22),\n",
       " ('sigmoid', 40, 0.23),\n",
       " ('sigmoid', 40, 0.24000000000000002),\n",
       " ('sigmoid', 40, 0.25),\n",
       " ('sigmoid', 40, 0.26),\n",
       " ('sigmoid', 40, 0.27),\n",
       " ('sigmoid', 40, 0.28),\n",
       " ('sigmoid', 40, 0.29000000000000004),\n",
       " ('sigmoid', 40, 0.3),\n",
       " ('sigmoid', 40, 0.31),\n",
       " ('sigmoid', 40, 0.32),\n",
       " ('sigmoid', 40, 0.33),\n",
       " ('sigmoid', 40, 0.34),\n",
       " ('sigmoid', 40, 0.35000000000000003),\n",
       " ('sigmoid', 40, 0.36000000000000004),\n",
       " ('sigmoid', 40, 0.37),\n",
       " ('sigmoid', 40, 0.38),\n",
       " ('sigmoid', 40, 0.39),\n",
       " ('sigmoid', 40, 0.4),\n",
       " ('sigmoid', 40, 0.41000000000000003),\n",
       " ('sigmoid', 40, 0.42000000000000004),\n",
       " ('sigmoid', 40, 0.43),\n",
       " ('sigmoid', 40, 0.44),\n",
       " ('sigmoid', 40, 0.45),\n",
       " ('sigmoid', 40, 0.46),\n",
       " ('sigmoid', 40, 0.47000000000000003),\n",
       " ('sigmoid', 40, 0.48000000000000004),\n",
       " ('sigmoid', 40, 0.49),\n",
       " ('sigmoid', 40, 0.5),\n",
       " ('sigmoid', 45, 0.01),\n",
       " ('sigmoid', 45, 0.02),\n",
       " ('sigmoid', 45, 0.03),\n",
       " ('sigmoid', 45, 0.04),\n",
       " ('sigmoid', 45, 0.05),\n",
       " ('sigmoid', 45, 0.060000000000000005),\n",
       " ('sigmoid', 45, 0.06999999999999999),\n",
       " ('sigmoid', 45, 0.08),\n",
       " ('sigmoid', 45, 0.09),\n",
       " ('sigmoid', 45, 0.09999999999999999),\n",
       " ('sigmoid', 45, 0.11),\n",
       " ('sigmoid', 45, 0.12),\n",
       " ('sigmoid', 45, 0.13),\n",
       " ('sigmoid', 45, 0.14),\n",
       " ('sigmoid', 45, 0.15000000000000002),\n",
       " ('sigmoid', 45, 0.16),\n",
       " ('sigmoid', 45, 0.17),\n",
       " ('sigmoid', 45, 0.18000000000000002),\n",
       " ('sigmoid', 45, 0.19),\n",
       " ('sigmoid', 45, 0.2),\n",
       " ('sigmoid', 45, 0.21000000000000002),\n",
       " ('sigmoid', 45, 0.22),\n",
       " ('sigmoid', 45, 0.23),\n",
       " ('sigmoid', 45, 0.24000000000000002),\n",
       " ('sigmoid', 45, 0.25),\n",
       " ('sigmoid', 45, 0.26),\n",
       " ('sigmoid', 45, 0.27),\n",
       " ('sigmoid', 45, 0.28),\n",
       " ('sigmoid', 45, 0.29000000000000004),\n",
       " ('sigmoid', 45, 0.3),\n",
       " ('sigmoid', 45, 0.31),\n",
       " ('sigmoid', 45, 0.32),\n",
       " ('sigmoid', 45, 0.33),\n",
       " ('sigmoid', 45, 0.34),\n",
       " ('sigmoid', 45, 0.35000000000000003),\n",
       " ('sigmoid', 45, 0.36000000000000004),\n",
       " ('sigmoid', 45, 0.37),\n",
       " ('sigmoid', 45, 0.38),\n",
       " ('sigmoid', 45, 0.39),\n",
       " ('sigmoid', 45, 0.4),\n",
       " ('sigmoid', 45, 0.41000000000000003),\n",
       " ('sigmoid', 45, 0.42000000000000004),\n",
       " ('sigmoid', 45, 0.43),\n",
       " ('sigmoid', 45, 0.44),\n",
       " ('sigmoid', 45, 0.45),\n",
       " ('sigmoid', 45, 0.46),\n",
       " ('sigmoid', 45, 0.47000000000000003),\n",
       " ('sigmoid', 45, 0.48000000000000004),\n",
       " ('sigmoid', 45, 0.49),\n",
       " ('sigmoid', 45, 0.5),\n",
       " ('sigmoid', 50, 0.01),\n",
       " ('sigmoid', 50, 0.02),\n",
       " ('sigmoid', 50, 0.03),\n",
       " ('sigmoid', 50, 0.04),\n",
       " ('sigmoid', 50, 0.05),\n",
       " ('sigmoid', 50, 0.060000000000000005),\n",
       " ('sigmoid', 50, 0.06999999999999999),\n",
       " ('sigmoid', 50, 0.08),\n",
       " ('sigmoid', 50, 0.09),\n",
       " ('sigmoid', 50, 0.09999999999999999),\n",
       " ('sigmoid', 50, 0.11),\n",
       " ('sigmoid', 50, 0.12),\n",
       " ('sigmoid', 50, 0.13),\n",
       " ('sigmoid', 50, 0.14),\n",
       " ('sigmoid', 50, 0.15000000000000002),\n",
       " ('sigmoid', 50, 0.16),\n",
       " ('sigmoid', 50, 0.17),\n",
       " ('sigmoid', 50, 0.18000000000000002),\n",
       " ('sigmoid', 50, 0.19),\n",
       " ('sigmoid', 50, 0.2),\n",
       " ('sigmoid', 50, 0.21000000000000002),\n",
       " ('sigmoid', 50, 0.22),\n",
       " ('sigmoid', 50, 0.23),\n",
       " ('sigmoid', 50, 0.24000000000000002),\n",
       " ('sigmoid', 50, 0.25),\n",
       " ('sigmoid', 50, 0.26),\n",
       " ('sigmoid', 50, 0.27),\n",
       " ('sigmoid', 50, 0.28),\n",
       " ('sigmoid', 50, 0.29000000000000004),\n",
       " ('sigmoid', 50, 0.3),\n",
       " ('sigmoid', 50, 0.31),\n",
       " ('sigmoid', 50, 0.32),\n",
       " ('sigmoid', 50, 0.33),\n",
       " ('sigmoid', 50, 0.34),\n",
       " ('sigmoid', 50, 0.35000000000000003),\n",
       " ('sigmoid', 50, 0.36000000000000004),\n",
       " ('sigmoid', 50, 0.37),\n",
       " ('sigmoid', 50, 0.38),\n",
       " ('sigmoid', 50, 0.39),\n",
       " ('sigmoid', 50, 0.4),\n",
       " ('sigmoid', 50, 0.41000000000000003),\n",
       " ('sigmoid', 50, 0.42000000000000004),\n",
       " ('sigmoid', 50, 0.43),\n",
       " ('sigmoid', 50, 0.44),\n",
       " ('sigmoid', 50, 0.45),\n",
       " ('sigmoid', 50, 0.46),\n",
       " ('sigmoid', 50, 0.47000000000000003),\n",
       " ('sigmoid', 50, 0.48000000000000004),\n",
       " ('sigmoid', 50, 0.49),\n",
       " ('sigmoid', 50, 0.5),\n",
       " ('sigmoid', 75, 0.01),\n",
       " ('sigmoid', 75, 0.02),\n",
       " ('sigmoid', 75, 0.03),\n",
       " ('sigmoid', 75, 0.04),\n",
       " ('sigmoid', 75, 0.05),\n",
       " ('sigmoid', 75, 0.060000000000000005),\n",
       " ('sigmoid', 75, 0.06999999999999999),\n",
       " ('sigmoid', 75, 0.08),\n",
       " ('sigmoid', 75, 0.09),\n",
       " ('sigmoid', 75, 0.09999999999999999),\n",
       " ('sigmoid', 75, 0.11),\n",
       " ('sigmoid', 75, 0.12),\n",
       " ('sigmoid', 75, 0.13),\n",
       " ('sigmoid', 75, 0.14),\n",
       " ('sigmoid', 75, 0.15000000000000002),\n",
       " ('sigmoid', 75, 0.16),\n",
       " ('sigmoid', 75, 0.17),\n",
       " ('sigmoid', 75, 0.18000000000000002),\n",
       " ('sigmoid', 75, 0.19),\n",
       " ('sigmoid', 75, 0.2),\n",
       " ('sigmoid', 75, 0.21000000000000002),\n",
       " ('sigmoid', 75, 0.22),\n",
       " ('sigmoid', 75, 0.23),\n",
       " ('sigmoid', 75, 0.24000000000000002),\n",
       " ('sigmoid', 75, 0.25),\n",
       " ('sigmoid', 75, 0.26),\n",
       " ('sigmoid', 75, 0.27),\n",
       " ('sigmoid', 75, 0.28),\n",
       " ('sigmoid', 75, 0.29000000000000004),\n",
       " ('sigmoid', 75, 0.3),\n",
       " ('sigmoid', 75, 0.31),\n",
       " ('sigmoid', 75, 0.32),\n",
       " ('sigmoid', 75, 0.33),\n",
       " ('sigmoid', 75, 0.34),\n",
       " ('sigmoid', 75, 0.35000000000000003),\n",
       " ('sigmoid', 75, 0.36000000000000004),\n",
       " ('sigmoid', 75, 0.37),\n",
       " ('sigmoid', 75, 0.38),\n",
       " ('sigmoid', 75, 0.39),\n",
       " ('sigmoid', 75, 0.4),\n",
       " ('sigmoid', 75, 0.41000000000000003),\n",
       " ('sigmoid', 75, 0.42000000000000004),\n",
       " ('sigmoid', 75, 0.43),\n",
       " ('sigmoid', 75, 0.44),\n",
       " ('sigmoid', 75, 0.45),\n",
       " ('sigmoid', 75, 0.46),\n",
       " ('sigmoid', 75, 0.47000000000000003),\n",
       " ('sigmoid', 75, 0.48000000000000004),\n",
       " ('sigmoid', 75, 0.49),\n",
       " ('sigmoid', 75, 0.5),\n",
       " ('sigmoid', 100, 0.01),\n",
       " ('sigmoid', 100, 0.02),\n",
       " ('sigmoid', 100, 0.03),\n",
       " ('sigmoid', 100, 0.04),\n",
       " ('sigmoid', 100, 0.05),\n",
       " ('sigmoid', 100, 0.060000000000000005),\n",
       " ('sigmoid', 100, 0.06999999999999999),\n",
       " ('sigmoid', 100, 0.08),\n",
       " ('sigmoid', 100, 0.09),\n",
       " ('sigmoid', 100, 0.09999999999999999),\n",
       " ('sigmoid', 100, 0.11),\n",
       " ('sigmoid', 100, 0.12),\n",
       " ('sigmoid', 100, 0.13),\n",
       " ('sigmoid', 100, 0.14),\n",
       " ('sigmoid', 100, 0.15000000000000002),\n",
       " ('sigmoid', 100, 0.16),\n",
       " ('sigmoid', 100, 0.17),\n",
       " ('sigmoid', 100, 0.18000000000000002),\n",
       " ('sigmoid', 100, 0.19),\n",
       " ('sigmoid', 100, 0.2),\n",
       " ('sigmoid', 100, 0.21000000000000002),\n",
       " ('sigmoid', 100, 0.22),\n",
       " ('sigmoid', 100, 0.23),\n",
       " ('sigmoid', 100, 0.24000000000000002),\n",
       " ('sigmoid', 100, 0.25),\n",
       " ('sigmoid', 100, 0.26),\n",
       " ('sigmoid', 100, 0.27),\n",
       " ('sigmoid', 100, 0.28),\n",
       " ('sigmoid', 100, 0.29000000000000004),\n",
       " ('sigmoid', 100, 0.3),\n",
       " ('sigmoid', 100, 0.31),\n",
       " ('sigmoid', 100, 0.32),\n",
       " ('sigmoid', 100, 0.33),\n",
       " ('sigmoid', 100, 0.34),\n",
       " ('sigmoid', 100, 0.35000000000000003),\n",
       " ('sigmoid', 100, 0.36000000000000004),\n",
       " ('sigmoid', 100, 0.37),\n",
       " ('sigmoid', 100, 0.38),\n",
       " ('sigmoid', 100, 0.39),\n",
       " ('sigmoid', 100, 0.4),\n",
       " ('sigmoid', 100, 0.41000000000000003),\n",
       " ('sigmoid', 100, 0.42000000000000004),\n",
       " ('sigmoid', 100, 0.43),\n",
       " ('sigmoid', 100, 0.44),\n",
       " ('sigmoid', 100, 0.45),\n",
       " ('sigmoid', 100, 0.46),\n",
       " ('sigmoid', 100, 0.47000000000000003),\n",
       " ('sigmoid', 100, 0.48000000000000004),\n",
       " ('sigmoid', 100, 0.49),\n",
       " ('sigmoid', 100, 0.5),\n",
       " ('relu', 2, 0.01),\n",
       " ('relu', 2, 0.02),\n",
       " ('relu', 2, 0.03),\n",
       " ('relu', 2, 0.04),\n",
       " ('relu', 2, 0.05),\n",
       " ('relu', 2, 0.060000000000000005),\n",
       " ('relu', 2, 0.06999999999999999),\n",
       " ('relu', 2, 0.08),\n",
       " ('relu', 2, 0.09),\n",
       " ('relu', 2, 0.09999999999999999),\n",
       " ('relu', 2, 0.11),\n",
       " ('relu', 2, 0.12),\n",
       " ('relu', 2, 0.13),\n",
       " ('relu', 2, 0.14),\n",
       " ('relu', 2, 0.15000000000000002),\n",
       " ('relu', 2, 0.16),\n",
       " ('relu', 2, 0.17),\n",
       " ('relu', 2, 0.18000000000000002),\n",
       " ('relu', 2, 0.19),\n",
       " ('relu', 2, 0.2),\n",
       " ('relu', 2, 0.21000000000000002),\n",
       " ('relu', 2, 0.22),\n",
       " ('relu', 2, 0.23),\n",
       " ('relu', 2, 0.24000000000000002),\n",
       " ('relu', 2, 0.25),\n",
       " ('relu', 2, 0.26),\n",
       " ('relu', 2, 0.27),\n",
       " ('relu', 2, 0.28),\n",
       " ('relu', 2, 0.29000000000000004),\n",
       " ('relu', 2, 0.3),\n",
       " ('relu', 2, 0.31),\n",
       " ('relu', 2, 0.32),\n",
       " ('relu', 2, 0.33),\n",
       " ('relu', 2, 0.34),\n",
       " ('relu', 2, 0.35000000000000003),\n",
       " ('relu', 2, 0.36000000000000004),\n",
       " ('relu', 2, 0.37),\n",
       " ('relu', 2, 0.38),\n",
       " ('relu', 2, 0.39),\n",
       " ('relu', 2, 0.4),\n",
       " ('relu', 2, 0.41000000000000003),\n",
       " ('relu', 2, 0.42000000000000004),\n",
       " ('relu', 2, 0.43),\n",
       " ('relu', 2, 0.44),\n",
       " ('relu', 2, 0.45),\n",
       " ('relu', 2, 0.46),\n",
       " ('relu', 2, 0.47000000000000003),\n",
       " ('relu', 2, 0.48000000000000004),\n",
       " ('relu', 2, 0.49),\n",
       " ('relu', 2, 0.5),\n",
       " ('relu', 5, 0.01),\n",
       " ('relu', 5, 0.02),\n",
       " ('relu', 5, 0.03),\n",
       " ('relu', 5, 0.04),\n",
       " ('relu', 5, 0.05),\n",
       " ('relu', 5, 0.060000000000000005),\n",
       " ('relu', 5, 0.06999999999999999),\n",
       " ('relu', 5, 0.08),\n",
       " ('relu', 5, 0.09),\n",
       " ('relu', 5, 0.09999999999999999),\n",
       " ('relu', 5, 0.11),\n",
       " ('relu', 5, 0.12),\n",
       " ('relu', 5, 0.13),\n",
       " ('relu', 5, 0.14),\n",
       " ('relu', 5, 0.15000000000000002),\n",
       " ('relu', 5, 0.16),\n",
       " ('relu', 5, 0.17),\n",
       " ('relu', 5, 0.18000000000000002),\n",
       " ('relu', 5, 0.19),\n",
       " ('relu', 5, 0.2),\n",
       " ('relu', 5, 0.21000000000000002),\n",
       " ('relu', 5, 0.22),\n",
       " ('relu', 5, 0.23),\n",
       " ('relu', 5, 0.24000000000000002),\n",
       " ('relu', 5, 0.25),\n",
       " ('relu', 5, 0.26),\n",
       " ('relu', 5, 0.27),\n",
       " ('relu', 5, 0.28),\n",
       " ('relu', 5, 0.29000000000000004),\n",
       " ('relu', 5, 0.3),\n",
       " ('relu', 5, 0.31),\n",
       " ('relu', 5, 0.32),\n",
       " ('relu', 5, 0.33),\n",
       " ('relu', 5, 0.34),\n",
       " ('relu', 5, 0.35000000000000003),\n",
       " ('relu', 5, 0.36000000000000004),\n",
       " ('relu', 5, 0.37),\n",
       " ('relu', 5, 0.38),\n",
       " ('relu', 5, 0.39),\n",
       " ('relu', 5, 0.4),\n",
       " ('relu', 5, 0.41000000000000003),\n",
       " ('relu', 5, 0.42000000000000004),\n",
       " ('relu', 5, 0.43),\n",
       " ('relu', 5, 0.44),\n",
       " ('relu', 5, 0.45),\n",
       " ('relu', 5, 0.46),\n",
       " ('relu', 5, 0.47000000000000003),\n",
       " ('relu', 5, 0.48000000000000004),\n",
       " ('relu', 5, 0.49),\n",
       " ('relu', 5, 0.5),\n",
       " ('relu', 10, 0.01),\n",
       " ('relu', 10, 0.02),\n",
       " ('relu', 10, 0.03),\n",
       " ('relu', 10, 0.04),\n",
       " ('relu', 10, 0.05),\n",
       " ('relu', 10, 0.060000000000000005),\n",
       " ('relu', 10, 0.06999999999999999),\n",
       " ('relu', 10, 0.08),\n",
       " ('relu', 10, 0.09),\n",
       " ('relu', 10, 0.09999999999999999),\n",
       " ('relu', 10, 0.11),\n",
       " ('relu', 10, 0.12),\n",
       " ('relu', 10, 0.13),\n",
       " ('relu', 10, 0.14),\n",
       " ('relu', 10, 0.15000000000000002),\n",
       " ('relu', 10, 0.16),\n",
       " ('relu', 10, 0.17),\n",
       " ('relu', 10, 0.18000000000000002),\n",
       " ('relu', 10, 0.19),\n",
       " ('relu', 10, 0.2),\n",
       " ('relu', 10, 0.21000000000000002),\n",
       " ('relu', 10, 0.22),\n",
       " ('relu', 10, 0.23),\n",
       " ('relu', 10, 0.24000000000000002),\n",
       " ('relu', 10, 0.25),\n",
       " ('relu', 10, 0.26),\n",
       " ('relu', 10, 0.27),\n",
       " ('relu', 10, 0.28),\n",
       " ('relu', 10, 0.29000000000000004),\n",
       " ('relu', 10, 0.3),\n",
       " ('relu', 10, 0.31),\n",
       " ('relu', 10, 0.32),\n",
       " ('relu', 10, 0.33),\n",
       " ('relu', 10, 0.34),\n",
       " ('relu', 10, 0.35000000000000003),\n",
       " ('relu', 10, 0.36000000000000004),\n",
       " ('relu', 10, 0.37),\n",
       " ('relu', 10, 0.38),\n",
       " ('relu', 10, 0.39),\n",
       " ('relu', 10, 0.4),\n",
       " ('relu', 10, 0.41000000000000003),\n",
       " ('relu', 10, 0.42000000000000004),\n",
       " ('relu', 10, 0.43),\n",
       " ('relu', 10, 0.44),\n",
       " ('relu', 10, 0.45),\n",
       " ('relu', 10, 0.46),\n",
       " ('relu', 10, 0.47000000000000003),\n",
       " ('relu', 10, 0.48000000000000004),\n",
       " ('relu', 10, 0.49),\n",
       " ('relu', 10, 0.5),\n",
       " ('relu', 15, 0.01),\n",
       " ('relu', 15, 0.02),\n",
       " ('relu', 15, 0.03),\n",
       " ('relu', 15, 0.04),\n",
       " ('relu', 15, 0.05),\n",
       " ('relu', 15, 0.060000000000000005),\n",
       " ('relu', 15, 0.06999999999999999),\n",
       " ('relu', 15, 0.08),\n",
       " ('relu', 15, 0.09),\n",
       " ('relu', 15, 0.09999999999999999),\n",
       " ('relu', 15, 0.11),\n",
       " ('relu', 15, 0.12),\n",
       " ('relu', 15, 0.13),\n",
       " ('relu', 15, 0.14),\n",
       " ('relu', 15, 0.15000000000000002),\n",
       " ('relu', 15, 0.16),\n",
       " ('relu', 15, 0.17),\n",
       " ('relu', 15, 0.18000000000000002),\n",
       " ('relu', 15, 0.19),\n",
       " ('relu', 15, 0.2),\n",
       " ('relu', 15, 0.21000000000000002),\n",
       " ('relu', 15, 0.22),\n",
       " ('relu', 15, 0.23),\n",
       " ('relu', 15, 0.24000000000000002),\n",
       " ('relu', 15, 0.25),\n",
       " ('relu', 15, 0.26),\n",
       " ('relu', 15, 0.27),\n",
       " ('relu', 15, 0.28),\n",
       " ('relu', 15, 0.29000000000000004),\n",
       " ('relu', 15, 0.3),\n",
       " ('relu', 15, 0.31),\n",
       " ('relu', 15, 0.32),\n",
       " ('relu', 15, 0.33),\n",
       " ('relu', 15, 0.34),\n",
       " ('relu', 15, 0.35000000000000003),\n",
       " ('relu', 15, 0.36000000000000004),\n",
       " ('relu', 15, 0.37),\n",
       " ('relu', 15, 0.38),\n",
       " ('relu', 15, 0.39),\n",
       " ('relu', 15, 0.4),\n",
       " ('relu', 15, 0.41000000000000003),\n",
       " ('relu', 15, 0.42000000000000004),\n",
       " ('relu', 15, 0.43),\n",
       " ('relu', 15, 0.44),\n",
       " ('relu', 15, 0.45),\n",
       " ('relu', 15, 0.46),\n",
       " ('relu', 15, 0.47000000000000003),\n",
       " ('relu', 15, 0.48000000000000004),\n",
       " ('relu', 15, 0.49),\n",
       " ('relu', 15, 0.5),\n",
       " ('relu', 20, 0.01),\n",
       " ('relu', 20, 0.02),\n",
       " ('relu', 20, 0.03),\n",
       " ('relu', 20, 0.04),\n",
       " ('relu', 20, 0.05),\n",
       " ('relu', 20, 0.060000000000000005),\n",
       " ('relu', 20, 0.06999999999999999),\n",
       " ('relu', 20, 0.08),\n",
       " ('relu', 20, 0.09),\n",
       " ('relu', 20, 0.09999999999999999),\n",
       " ('relu', 20, 0.11),\n",
       " ('relu', 20, 0.12),\n",
       " ('relu', 20, 0.13),\n",
       " ('relu', 20, 0.14),\n",
       " ('relu', 20, 0.15000000000000002),\n",
       " ('relu', 20, 0.16),\n",
       " ('relu', 20, 0.17),\n",
       " ('relu', 20, 0.18000000000000002),\n",
       " ('relu', 20, 0.19),\n",
       " ('relu', 20, 0.2),\n",
       " ('relu', 20, 0.21000000000000002),\n",
       " ('relu', 20, 0.22),\n",
       " ('relu', 20, 0.23),\n",
       " ('relu', 20, 0.24000000000000002),\n",
       " ('relu', 20, 0.25),\n",
       " ('relu', 20, 0.26),\n",
       " ('relu', 20, 0.27),\n",
       " ('relu', 20, 0.28),\n",
       " ('relu', 20, 0.29000000000000004),\n",
       " ('relu', 20, 0.3),\n",
       " ('relu', 20, 0.31),\n",
       " ('relu', 20, 0.32),\n",
       " ('relu', 20, 0.33),\n",
       " ('relu', 20, 0.34),\n",
       " ('relu', 20, 0.35000000000000003),\n",
       " ('relu', 20, 0.36000000000000004),\n",
       " ('relu', 20, 0.37),\n",
       " ('relu', 20, 0.38),\n",
       " ('relu', 20, 0.39),\n",
       " ('relu', 20, 0.4),\n",
       " ('relu', 20, 0.41000000000000003),\n",
       " ('relu', 20, 0.42000000000000004),\n",
       " ('relu', 20, 0.43),\n",
       " ('relu', 20, 0.44),\n",
       " ('relu', 20, 0.45),\n",
       " ('relu', 20, 0.46),\n",
       " ('relu', 20, 0.47000000000000003),\n",
       " ('relu', 20, 0.48000000000000004),\n",
       " ('relu', 20, 0.49),\n",
       " ('relu', 20, 0.5),\n",
       " ('relu', 25, 0.01),\n",
       " ('relu', 25, 0.02),\n",
       " ('relu', 25, 0.03),\n",
       " ('relu', 25, 0.04),\n",
       " ('relu', 25, 0.05),\n",
       " ('relu', 25, 0.060000000000000005),\n",
       " ('relu', 25, 0.06999999999999999),\n",
       " ('relu', 25, 0.08),\n",
       " ('relu', 25, 0.09),\n",
       " ('relu', 25, 0.09999999999999999),\n",
       " ('relu', 25, 0.11),\n",
       " ('relu', 25, 0.12),\n",
       " ('relu', 25, 0.13),\n",
       " ('relu', 25, 0.14),\n",
       " ('relu', 25, 0.15000000000000002),\n",
       " ('relu', 25, 0.16),\n",
       " ('relu', 25, 0.17),\n",
       " ('relu', 25, 0.18000000000000002),\n",
       " ('relu', 25, 0.19),\n",
       " ('relu', 25, 0.2),\n",
       " ('relu', 25, 0.21000000000000002),\n",
       " ('relu', 25, 0.22),\n",
       " ('relu', 25, 0.23),\n",
       " ('relu', 25, 0.24000000000000002),\n",
       " ('relu', 25, 0.25),\n",
       " ('relu', 25, 0.26),\n",
       " ('relu', 25, 0.27),\n",
       " ('relu', 25, 0.28),\n",
       " ('relu', 25, 0.29000000000000004),\n",
       " ('relu', 25, 0.3),\n",
       " ('relu', 25, 0.31),\n",
       " ('relu', 25, 0.32),\n",
       " ('relu', 25, 0.33),\n",
       " ('relu', 25, 0.34),\n",
       " ('relu', 25, 0.35000000000000003),\n",
       " ('relu', 25, 0.36000000000000004),\n",
       " ('relu', 25, 0.37),\n",
       " ('relu', 25, 0.38),\n",
       " ('relu', 25, 0.39),\n",
       " ('relu', 25, 0.4),\n",
       " ('relu', 25, 0.41000000000000003),\n",
       " ('relu', 25, 0.42000000000000004),\n",
       " ('relu', 25, 0.43),\n",
       " ('relu', 25, 0.44),\n",
       " ('relu', 25, 0.45),\n",
       " ('relu', 25, 0.46),\n",
       " ('relu', 25, 0.47000000000000003),\n",
       " ('relu', 25, 0.48000000000000004),\n",
       " ('relu', 25, 0.49),\n",
       " ('relu', 25, 0.5),\n",
       " ('relu', 30, 0.01),\n",
       " ('relu', 30, 0.02),\n",
       " ('relu', 30, 0.03),\n",
       " ('relu', 30, 0.04),\n",
       " ('relu', 30, 0.05),\n",
       " ('relu', 30, 0.060000000000000005),\n",
       " ('relu', 30, 0.06999999999999999),\n",
       " ('relu', 30, 0.08),\n",
       " ('relu', 30, 0.09),\n",
       " ('relu', 30, 0.09999999999999999),\n",
       " ('relu', 30, 0.11),\n",
       " ('relu', 30, 0.12),\n",
       " ('relu', 30, 0.13),\n",
       " ('relu', 30, 0.14),\n",
       " ('relu', 30, 0.15000000000000002),\n",
       " ('relu', 30, 0.16),\n",
       " ('relu', 30, 0.17),\n",
       " ('relu', 30, 0.18000000000000002),\n",
       " ('relu', 30, 0.19),\n",
       " ('relu', 30, 0.2),\n",
       " ('relu', 30, 0.21000000000000002),\n",
       " ('relu', 30, 0.22),\n",
       " ('relu', 30, 0.23),\n",
       " ('relu', 30, 0.24000000000000002),\n",
       " ('relu', 30, 0.25),\n",
       " ('relu', 30, 0.26),\n",
       " ('relu', 30, 0.27),\n",
       " ('relu', 30, 0.28),\n",
       " ('relu', 30, 0.29000000000000004),\n",
       " ('relu', 30, 0.3),\n",
       " ('relu', 30, 0.31),\n",
       " ('relu', 30, 0.32),\n",
       " ('relu', 30, 0.33),\n",
       " ('relu', 30, 0.34),\n",
       " ('relu', 30, 0.35000000000000003),\n",
       " ('relu', 30, 0.36000000000000004),\n",
       " ('relu', 30, 0.37),\n",
       " ('relu', 30, 0.38),\n",
       " ('relu', 30, 0.39),\n",
       " ('relu', 30, 0.4),\n",
       " ('relu', 30, 0.41000000000000003),\n",
       " ('relu', 30, 0.42000000000000004),\n",
       " ('relu', 30, 0.43),\n",
       " ('relu', 30, 0.44),\n",
       " ('relu', 30, 0.45),\n",
       " ('relu', 30, 0.46),\n",
       " ('relu', 30, 0.47000000000000003),\n",
       " ('relu', 30, 0.48000000000000004),\n",
       " ('relu', 30, 0.49),\n",
       " ('relu', 30, 0.5),\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product(hyperparameter_space.get('activation'), \\\n",
    "             hyperparameter_space.get('units'),\\\n",
    "#              [50],\n",
    "             hyperparameter_space.get('dropout_rate')\n",
    "#   [0.5]\n",
    "             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "366ddf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space_mango_opt = {\n",
    "    'nb_hidden_layers': [3],\n",
    "    'layer_param_0':[{'dropout_rate':dropout_rate, \\\n",
    "                      'units':unit, \\\n",
    "                      'activation':activation, \\\n",
    "                      'use_bias':True, \\\n",
    "                      'kernel_initializer':'glorot_uniform'} \n",
    "                     \n",
    "                     for activation, unit, dropout_rate in \n",
    "                     list(product(hyperparameter_space.get('activation'), \\\n",
    "                     hyperparameter_space.get('units'),\\\n",
    "                     hyperparameter_space.get('dropout_rate')\n",
    "            ))\n",
    "                    \n",
    "                    ],\n",
    "    \n",
    "    'optimizer': ['adam'],\n",
    " 'callbacks': [hyperparameter_space.get('callbacks')],\n",
    " 'batch_size': [256]\n",
    "    \n",
    "    \n",
    "}\n",
    "hyperparameter_space_mango_opt['layer_param_1'] = hyperparameter_space_mango_opt.get('layer_param_0')\n",
    "hyperparameter_space_mango_opt['layer_param_2'] = hyperparameter_space_mango_opt.get('layer_param_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6111043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @scheduler.parallel(n_jobs=N_JOBS_MANGO_PARALLEL)\n",
    "def objective_nn(hyperparameters:Dict[str, Any]) -> List[float]:\n",
    "    global x_train, y_train, x_val, y_val, exp_train, exp_val\n",
    "    \n",
    "    results = []\n",
    "    for hyperparams in hyperparameters:\n",
    "        model = fit_feed_forward_neural_network(\n",
    "            x_train, y_train, x_val, y_val, params=hyperparams\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        pred_val = model.predict(x_val)\n",
    "        error = mean_poisson_deviance(y_val, pred_val, sample_weight=exp_val)\n",
    "        results.append(error)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a0e13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(hyperparameter_space_mango_opt, objective_nn, dict(num_iteration=1, initial_random=41))  # Initialize Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c70ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation_results = tuner.minimize() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511d90c",
   "metadata": {},
   "source": [
    "### 3. Bayesian optimization with Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "856bcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2 + x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ddbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = hp.uniform('x', -2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cf3f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... (more hidden) ...\n",
      "Optimal value of x: {'x': -0.5002999730043602}\n"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    fn=f,  \n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=1000\n",
    ")\n",
    "\n",
    "print(f\"Optimal value of x: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43be196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x1a04af75d00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49ddd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.linspace(-100, 100, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca46ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, f(x))\n",
    "plt.axvline(best.get('x'), linestyle='dashed', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf56312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
